# -*- coding: utf-8 -*-
"""Stacking.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jDxlIk4zBr09wZPwNMr7fC4TLiGCX3Rj
"""

!unzip DeepDRiD.zip

# -*- coding: utf-8 -*-
"""
Created on Sat Dec 28 11:01:28 2024

@author: amsal
"""

import copy
import os
import random
import sys

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from PIL import Image
from sklearn.metrics import cohen_kappa_score, precision_score, recall_score, accuracy_score
from torch.utils.data import Dataset, DataLoader
from torchvision import models, transforms
from torchvision.transforms.functional import to_pil_image
from tqdm import tqdm

num_classes = 5  # 5 DR levels
num_epochs = 23

# Hyper Parameters
batch_size1 = 24
learning_rate1 = 0.0001

batch_size2 = 24
learning_rate2 = 0.0001

batch_size3 = 24
learning_rate3 = 0.0001

batch_size4 = 22
learning_rate4 = 0.0001

batches = [batch_size1, batch_size2, batch_size3, batch_size4]
learning_rates = [learning_rate1, learning_rate2, learning_rate3, learning_rate4]

class RetinopathyDataset(Dataset):
    def __init__(self, ann_file, image_dir, transform=None, mode='single', test=False):
        self.ann_file = ann_file
        self.image_dir = image_dir
        self.transform = transform
        self.test = test
        self.mode = mode

        if self.mode == 'single':
            self.data = self.load_data()
        else:
            self.data = self.load_data_dual()

    def __len__(self):
        return len(self.data)

    def __getitem__(self, index):
        if self.mode == 'single':
            return self.get_item(index)
        else:
            return self.get_item_dual(index)

    # 1. single image
    def load_data(self):
        df = pd.read_csv(self.ann_file)
        data = []
        for _, row in df.iterrows():
            file_info = dict()
            file_info['img_path'] = os.path.join(self.image_dir, row['img_path'])
            if not self.test:
                file_info['dr_level'] = int(row['patient_DR_Level'])
            data.append(file_info)
        return data

    def get_item(self, index):
        data = self.data[index]
        img = Image.open(data['img_path']).convert('RGB')
        if self.transform:
            img = self.transform(img)

        if not self.test:
            label = torch.tensor(data['dr_level'], dtype=torch.int64)
            return img, label
        else:
            return img

    # 2. dual image
    def load_data_dual(self):
        df = pd.read_csv(self.ann_file)
        df['prefix'] = df['image_id'].str.split('_').str[0]  # The patient id of each image
        df['suffix'] = df['image_id'].str.split('_').str[1].str[0]  # The left or right eye
        grouped = df.groupby(['prefix', 'suffix'])

        data = []
        for (prefix, suffix), group in grouped:
            file_info = dict()
            file_info['img_path1'] = os.path.join(self.image_dir, group.iloc[0]['img_path'])
            file_info['img_path2'] = os.path.join(self.image_dir, group.iloc[1]['img_path'])
            if not self.test:
                file_info['dr_level'] = int(group.iloc[0]['patient_DR_Level'])
            data.append(file_info)
        return data

    def get_item_dual(self, index):
        data = self.data[index]
        img1 = Image.open(data['img_path1']).convert('RGB')
        img2 = Image.open(data['img_path2']).convert('RGB')

        if self.transform:
            img1 = self.transform(img1)
            img2 = self.transform(img2)

        if not self.test:
            label = torch.tensor(data['dr_level'], dtype=torch.int64)
            return [img1, img2], label
        else:
            return [img1, img2]

class CutOut(object):
    def __init__(self, mask_size, p=0.5):
        self.mask_size = mask_size
        self.p = p

    def __call__(self, img):
        if np.random.rand() > self.p:
            return img

        if not isinstance(img, torch.Tensor):
            raise TypeError('Input image must be a torch.Tensor')

        h, w = img.shape[1], img.shape[2]
        mask_size_half = self.mask_size // 2
        offset = 1 if self.mask_size % 2 == 0 else 0

        cx = np.random.randint(mask_size_half, w + offset - mask_size_half)
        cy = np.random.randint(mask_size_half, h + offset - mask_size_half)

        xmin, xmax = cx - mask_size_half, cx + mask_size_half + offset
        ymin, ymax = cy - mask_size_half, cy + mask_size_half + offset
        xmin, xmax = max(0, xmin), min(w, xmax)
        ymin, ymax = max(0, ymin), min(h, ymax)

        img[:, ymin:ymax, xmin:xmax] = 0
        return img

class SLORandomPad:
    def __init__(self, size):
        self.size = size

    def __call__(self, img):
        pad_width = max(0, self.size[0] - img.width)
        pad_height = max(0, self.size[1] - img.height)
        pad_left = random.randint(0, pad_width)
        pad_top = random.randint(0, pad_height)
        pad_right = pad_width - pad_left
        pad_bottom = pad_height - pad_top
        return transforms.functional.pad(img, (pad_left, pad_top, pad_right, pad_bottom))

class FundRandomRotate:
    def __init__(self, prob, degree):
        self.prob = prob
        self.degree = degree

    def __call__(self, img):
        if random.random() < self.prob:
            angle = random.uniform(-self.degree, self.degree)
            return transforms.functional.rotate(img, angle)
        return img

transform_train = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.RandomCrop((210, 210)),
    SLORandomPad((224, 224)),
    FundRandomRotate(prob=0.5, degree=30),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.5),
    transforms.ColorJitter(brightness=(0.1, 0.9)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

transform_test = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

def train_model(model, train_loader, val_loader, device, criterion, optimizer, lr_scheduler, num_epochs=25, checkpoint_path='model.pth'):
    best_model = model.state_dict()
    best_epoch = None
    best_val_kappa = -1.0

    for epoch in range(1, num_epochs + 1):
        print(f'\nEpoch {epoch}/{num_epochs}')
        running_loss = []
        all_preds = []
        all_labels = []

        model.train()

        with tqdm(total=len(train_loader), desc=f'Training', unit=' batch', file=sys.stdout) as pbar:
            for images, labels in train_loader:
                if not isinstance(images, list):
                    images = images.to(device)
                else:
                    images = [x.to(device) for x in images]

                labels = labels.to(device)

                optimizer.zero_grad()

                outputs = model(images)
                loss = criterion(outputs, labels.long())

                loss.backward()
                optimizer.step()

                preds = torch.argmax(outputs, 1)
                all_preds.extend(preds.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())

                running_loss.append(loss.item())

                pbar.set_postfix({'lr': f'{optimizer.param_groups[0]["lr"]:.1e}', 'Loss': f'{loss.item():.4f}'})
                pbar.update(1)

        lr_scheduler.step()

        epoch_loss = sum(running_loss) / len(running_loss)

        train_metrics = compute_metrics(all_preds, all_labels, per_class=True)
        kappa, accuracy, precision, recall = train_metrics[:4]

        print(f'[Train] Kappa: {kappa:.4f} Accuracy: {accuracy:.4f} Precision: {precision:.4f} Recall: {recall:.4f} Loss: {epoch_loss:.4f}')

        if len(train_metrics) > 4:
            precision_per_class, recall_per_class = train_metrics[4:]
            for i, (precision, recall) in enumerate(zip(precision_per_class, recall_per_class)):
                print(f'[Train] Class {i}: Precision: {precision:.4f}, Recall: {recall:.4f}')

        val_metrics = evaluate_model(model, val_loader, device)
        val_kappa, val_accuracy, val_precision, val_recall = val_metrics[:4]
        print(f'[Val] Kappa: {val_kappa:.4f} Accuracy: {val_accuracy:.4f} Precision: {val_precision:.4f} Recall: {val_recall:.4f}')

        if val_kappa > best_val_kappa:
            best_val_kappa = val_kappa
            best_epoch = epoch
            best_model = model.state_dict()
            torch.save(best_model, checkpoint_path)

    print(f'[Val] Best kappa: {best_val_kappa:.4f}, Epoch {best_epoch}')

    return model

def evaluate_model(model, test_loader, device, test_only=False, prediction_path='./test_predictions.csv'):
    model.eval()

    all_preds = []
    all_labels = []
    all_image_ids = []

    with tqdm(total=len(test_loader), desc=f'Evaluating', unit=' batch', file=sys.stdout) as pbar:
        for i, data in enumerate(test_loader):
            if test_only:
                images = data
            else:
                images, labels = data
                prediction_path = './test_predictions_{model.__class__.__name__}.csv'

            if not isinstance(images, list):
                images = images.to(device)
            else:
                images = [x.to(device) for x in images]

            with torch.no_grad():
                outputs = model(images)
                preds = torch.argmax(outputs, 1)

            if not isinstance(images, list):
                all_preds.extend(preds.cpu().numpy())
                image_ids = [os.path.basename(test_loader.dataset.data[idx]['img_path']) for idx in range(i * test_loader.batch_size, i * test_loader.batch_size + len(images))]
                all_image_ids.extend(image_ids)
                if not test_only:
                    all_labels.extend(labels.numpy())
            else:
                for k in range(2):
                    all_preds.extend(preds.cpu().numpy())
                    image_ids = [os.path.basename(test_loader.dataset.data[idx][f'img_path{k + 1}']) for idx in range(i * test_loader.batch_size, i * test_loader.batch_size + len(images[k]))]
                    all_image_ids.extend(image_ids)
                    if not test_only:
                        all_labels.extend(labels.numpy())

            pbar.update(1)

    if test_only:
        df = pd.DataFrame({'ID': all_image_ids, 'TARGET': all_preds})
        df.to_csv(prediction_path, index=False)
        print(f'[Test] Save predictions to {os.path.abspath(prediction_path)}')
    else:
        metrics = compute_metrics(all_preds, all_labels)
        return metrics

def compute_metrics(preds, labels, per_class=False):
    kappa = cohen_kappa_score(labels, preds, weights='quadratic')
    accuracy = accuracy_score(labels, preds)
    precision = precision_score(labels, preds, average='weighted', zero_division=0)
    recall = recall_score(labels, preds, average='weighted', zero_division=0)

    if per_class:
        precision_per_class = precision_score(labels, preds, average=None, zero_division=0)
        recall_per_class = recall_score(labels, preds, average=None, zero_division=0)
        return kappa, accuracy, precision, recall, precision_per_class, recall_per_class

    return kappa, accuracy, precision, recall

class MyModelResnet1(nn.Module):
    def __init__(self, num_classes=5, dropout_rate=0.62):
        super().__init__()
        self.backbone = models.resnet18(pretrained=True)
        state_dict = torch.load('resnet18.pth', map_location='cpu')
        self.backbone.load_state_dict(state_dict, strict=False)
        self.backbone.fc = nn.Identity()

        self.fc = nn.Sequential(
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(p=dropout_rate),
            nn.Linear(256, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(p=dropout_rate),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        x = self.backbone(x)
        x = self.fc(x)
        return x

class MyDualModelResnet1(nn.Module):
    def __init__(self, num_classes=5, dropout_rate=0.6):
        super().__init__()
        backbone = models.resnet18(pretrained=True)
        state_dict = torch.load('resnet18.pth', map_location='cpu')
        backbone.load_state_dict(state_dict, strict=False)
        backbone.fc = nn.Identity()

        self.backbone1 = copy.deepcopy(backbone)
        self.backbone2 = copy.deepcopy(backbone)

        self.fc = nn.Sequential(
            nn.Linear(512 * 2, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(p=dropout_rate),
            nn.Linear(256, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(p=dropout_rate),
            nn.Linear(128, num_classes)
        )

    def forward(self, images):
        image1, image2 = images
        x1 = self.backbone1(image1)
        x2 = self.backbone2(image2)
        x = torch.cat((x1, x2), dim=1)
        x = self.fc(x)
        return x

class MyModelResnet3(nn.Module):
    def __init__(self, num_classes=5, dropout_rate=0.62):
        super().__init__()
        self.backbone = models.resnet18(pretrained=True)
        state_dict = torch.load('resnet18.pth', map_location='cpu')
        self.backbone.load_state_dict(state_dict, strict=False)
        self.backbone.fc = nn.Identity()

        self.fc = nn.Sequential(
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(p=dropout_rate),
            nn.Linear(256, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(p=dropout_rate),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        x = self.backbone(x)
        x = self.fc(x)
        return x

class MyDualModelResnet3(nn.Module):
    def __init__(self, num_classes=5, dropout_rate=0.6):
        super().__init__()
        backbone = models.resnet18(pretrained=True)
        state_dict = torch.load('resnet18.pth', map_location='cpu')
        backbone.load_state_dict(state_dict, strict=False)
        backbone.fc = nn.Identity()

        self.backbone1 = copy.deepcopy(backbone)
        self.backbone2 = copy.deepcopy(backbone)

        self.fc = nn.Sequential(
            nn.Linear(512 * 2, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(p=dropout_rate),
            nn.Linear(256, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(p=dropout_rate),
            nn.Linear(128, num_classes)
        )

    def forward(self, images):
        image1, image2 = images
        x1 = self.backbone1(image1)
        x2 = self.backbone2(image2)
        x = torch.cat((x1, x2), dim=1)
        x = self.fc(x)
        return x

class MyModeldense121(nn.Module):
    def __init__(self, num_classes=5, dropout_rate=0.73):
        super().__init__()
        self.backbone = models.densenet121(pretrained=True)
        state_dict = torch.load('model_3_denseNet.pth', map_location='cpu')
        self.backbone.load_state_dict(state_dict, strict=False)
        self.feature_dim = self.backbone.classifier.in_features
        self.backbone.classifier = nn.Identity()

        self.num_classes = num_classes
        self.dropout_rate = dropout_rate

        self.classifier = nn.Sequential(
            nn.Linear(self.feature_dim, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(p=self.dropout_rate),
            nn.Linear(256, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(p=self.dropout_rate),
            nn.Linear(128, self.num_classes)
        )

    def forward(self, x):
        x = self.backbone(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x

class MyDualModeldense121(nn.Module):
    def __init__(self, num_classes=5, dropout_rate=0.7):
        super().__init__()
        backbone = models.densenet121(pretrained=True)
        state_dict = torch.load('model_3_denseNet.pth', map_location='cpu')
        backbone.load_state_dict(state_dict, strict=False)
        self.feature_dim = backbone.classifier.in_features
        backbone.classifier = nn.Identity()

        self.backbone1 = copy.deepcopy(backbone)
        self.backbone2 = copy.deepcopy(backbone)

        self.num_classes = num_classes
        self.dropout_rate = dropout_rate

        self.fc = nn.Sequential(
            nn.Linear(self.feature_dim * 2, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(p=self.dropout_rate),
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(p=self.dropout_rate),
            nn.Linear(256, self.num_classes)
        )

    def forward(self, images):
        image1, image2 = images
        x1 = self.backbone1(image1)
        x2 = self.backbone2(image2)
        x1 = torch.flatten(x1, 1)
        x2 = torch.flatten(x2, 1)
        x = torch.cat((x1, x2), dim=1)
        x = self.fc(x)
        return x

class MetaModel(nn.Module):
    def __init__(self):
        super(MetaModel, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(15, 64),  # 15 = 5 (ResNet1) + 5 (DenseNet) + 5 (ResNet3)
            nn.ReLU(),
            nn.Dropout(p=0.5),
            nn.Linear(64, 5)   # Change 10 to your number of classes
        )

    def forward(self, resnet_out1, densenet_out, resnet_out3):
        combined = torch.cat((resnet_out1, densenet_out, resnet_out3), dim=1)
        output = self.fc(combined)
        return output

class StackingModel(nn.Module):
    def __init__(self, models):
        super(StackingModel, self).__init__()
        self.resnet18_1 = models[0]
        self.densenet121 = models[1]
        self.resnet18_3 = models[2]
        self.meta_model = MetaModel()

    def forward(self, x):
        resnet_out1 = self.resnet18_1(x)
        resnet_out3 = self.resnet18_3(x)
        densenet_out = self.densenet121(x)
        output = self.meta_model(resnet_out1, densenet_out, resnet_out3)
        return output


class DualStackingModel(nn.Module):
    def __init__(self, models):
        super(DualStackingModel, self).__init__()
        self.resnet18_1 = models[0]
        self.densenet121 = models[1]
        self.resnet18_3 = models[2]
        self.meta_model = MetaModel()

    def forward(self, x):
        # Ensure the input is a tuple of two images for dual models
        if isinstance(x, list) or isinstance(x, tuple):
            # If x is already a list or tuple, use it directly
            resnet_out1 = self.resnet18_1(x)
            resnet_out3 = self.resnet18_3(x)
            densenet_out = self.densenet121(x)
        else:
            # If x is a single tensor, duplicate it to create a tuple
            resnet_out1 = self.resnet18_1((x, x))
            resnet_out3 = self.resnet18_3((x, x))
            densenet_out = self.densenet121((x, x))

        output = self.meta_model(resnet_out1, densenet_out, resnet_out3)
        return output

if __name__ == '__main__':
    mode1 = 'double'
    mode2 = 'double'
    mode3 = 'double'
    mode4 = 'double'


    modes = [mode1, mode2, mode3, mode4]

    if mode1 == 'single':
        model1 = MyModelResnet1()
    else:
        model1 = MyDualModelResnet1()

    if mode2 == 'single':
        model2 = MyModeldense121()
    else:
        model2 = MyDualModeldense121()

    if mode3 == 'single':
        model3 = MyModelResnet3()
    else:
        model3 = MyDualModelResnet3()

    models = [model1, model2, model3]

    if mode4 == 'single':
        metaModel = StackingModel(models)

    else:
        metaModel = DualStackingModel(models)

    models.append(metaModel)

    print(f'model1:{model1}   model2:{model2}   model3:{model3}  metaModel:{metaModel}\n')
    print(f'Pipeline Mode1:{mode1} Pipeline Mode2:{mode2} Pipeline Mode3:{mode3} Pipeline Mode4:{metaModel}')

    for mode, model, batch_size, learning_rate in zip(modes, models, batches, learning_rates):
        train_dataset = RetinopathyDataset('./DeepDRiD/train.csv', './DeepDRiD/train/', transform_train, mode)
        val_dataset = RetinopathyDataset('./DeepDRiD/val.csv', './DeepDRiD/val/', transform_test, mode)
        test_dataset = RetinopathyDataset('./DeepDRiD/test.csv', './DeepDRiD/test/', transform_test, mode, test=True)

        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

        criterion = nn.CrossEntropyLoss()

        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print('Device:', device)

        model = model.to(device)

        optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)
        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)

        model = train_model(
            model, train_loader, val_loader, device, criterion, optimizer,
            lr_scheduler=lr_scheduler, num_epochs=num_epochs,
            checkpoint_path=f'./model_{model.__class__.__name__}.pth'
        )

        state_dict = torch.load(f'./model_{model.__class__.__name__}.pth', map_location='cpu')
        model.load_state_dict(state_dict, strict=True)

        evaluate_model(model, test_loader, device, test_only=True)